train_losses,val_losses
30.289657409505065,30.183192431926727
29.64773086466399,28.459684133529663
29.1077440064997,29.20218002796173
28.818159178058448,28.320686757564545
28.417438425627466,28.23869752883911
28.0627431360428,27.72784048318863
27.71160228226957,27.43096685409546
27.49921664309247,27.183350026607513
27.02997464217325,26.508709371089935
26.6139511094823,26.081142365932465
26.297971644011255,25.58670449256897
26.033140406489796,25.472767233848572
25.684496353529525,24.74488401412964
25.222210806035488,24.498558938503265
24.925226734202102,24.213752150535583
24.470530771275858,23.584533751010895
24.004919954890457,23.58007925748825
23.56912826728142,23.025641679763794
23.174065620449515,22.48609048128128
22.75922205779052,21.980953693389893
22.140229350731467,21.02022272348404
21.646220115580167,20.831030011177063
21.18869883309904,19.88502722978592
20.76154380336775,19.452780842781067
20.107048299388953,19.13313639163971
19.640168821260175,18.817043006420135
19.0671988551727,17.976068437099457
18.58691475824105,17.209277480840683
17.934785008006248,16.998899549245834
17.474456508812956,16.118553698062897
17.05167429981707,15.1532142162323
16.39404113606626,16.833817034959793
15.821236627381891,27.359055250883102
15.141656322411372,14.224409729242325
14.625479111043584,12.780625492334366
14.15289165116714,12.195756018161774
13.575852590947813,11.666420459747314
12.985896446526686,11.150484770536423
12.374269319174553,10.505854785442352
11.87831790761167,9.743317186832428
11.410457526237515,9.105571791529655
10.950608692983716,8.682549074292183
10.304168864077097,8.145773693919182
9.953446189703891,7.345782697200775
9.385853769091948,7.03215429186821
8.894588998204025,6.285010918974876
8.600533213903896,5.863700345158577
7.962924758734652,5.696433842182159
7.647569159171759,5.103917792439461
7.343717116902307,4.619287416338921

train_losses,val_losses
0.9110488982427688,0.891276932344204
0.8860774038600273,0.8760257072565032
0.8660113843930822,0.8547527353938033
0.8450448079174068,0.8328907409819161
0.8157319754159369,0.7894219574404926
0.7780503576304637,0.7601154090427771
0.7535119350264673,0.7426515410586101
0.7370566475959052,0.7258872607859169
0.7262562170320628,0.7158328432862352
0.7153382080752834,0.7080148560244862
0.7083848316653245,0.7006133765709109
0.7008708061004172,0.6923745761557323
0.6951433578316046,0.6872477567777401
0.6898037019230071,0.6837635192929244
0.6852196431484352,0.6772476565547105
0.6801051860763914,0.6716436591090226
0.6748171121084772,0.6702036486893166
0.6711824132471669,0.6639179834505406
0.6681303107008643,0.6606666758293058
0.6644160974593389,0.6587626178090166
0.6606695387639157,0.6559527574515924
0.6593595520979693,0.6502374824954242
0.6562402980668204,0.651145594875987
0.6529414194781764,0.6473292105081605
0.650236756217723,0.6477238172438087
0.6478246463399355,0.6433114598437053
0.6458687116499661,0.6412249927113696
0.6438028266640747,0.6373670915277992
0.6427393951383578,0.639795695136233
0.6400778197917808,0.6374481073239955
0.6380161064822658,0.6367069671793681
0.6366986912124011,0.6321595296627138
0.6340840123137649,0.6297427662988988
0.6334424421900795,0.6322938683556347
0.6307562172818346,0.6279461209366961
0.6296254374543014,0.6238493294250674
0.6282215530369557,0.6251517432491954
0.6268219893481456,0.6234743813189064
0.6253045711387583,0.620327898641912
0.6238329375682234,0.62307231891446

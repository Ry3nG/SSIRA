train_losses,val_losses
0.8301156400558874,0.7329327027972151
0.696497323049098,0.6686273478880161
0.6563192492293328,0.640595002872188
0.6333877202315429,0.6267489805454161
0.6180944514182425,0.6129096397539464
0.6040640859720633,0.5981047415151829
0.5930292973506082,0.5875560306921238
0.5842084837021287,0.5774856834876828
0.5741749726927158,0.5709656055380659
0.5683702080673778,0.5669692304076218
0.5629062447504899,0.5564136897645345
0.5571172986294806,0.5540743557418265
0.5531564003106245,0.5509541645282652
0.5503830798354346,0.5498059929870978
0.5578986539975884,0.5522910211144424
0.5520055475308723,0.5426926496552258
0.5444057832673653,0.5425543203586485
0.541235465441168,0.5372700502232808
0.5385409111214667,0.5340719470163671
0.5378811301797936,0.5452922509937752
0.5349172013475723,0.5286200337293672
0.5322082800041769,0.5337487924389723
0.530583257911746,0.5323097763991937
0.529268437900494,0.5287905989623651
0.5259403414332989,0.525773443826815
0.5246540043771881,0.5267358989250369
0.5227439886669523,0.5243578218832249
0.5222960974752289,0.524322839771829
0.5195760137795173,0.5218656281145607
0.518487574129375,0.5228362243349959
0.5173596377993367,0.5158636075694386
0.515133478208301,0.5153069888673177
0.5200783479766747,0.5145655521532384
0.5132431490826852,0.5150718819804307
0.5127768661711634,0.5097842027501363
0.5103929221783716,0.5123849743750037
0.5092205170964458,0.5093558895878676
0.50870109902522,0.5054794070197315
0.5083395004579702,0.5064959831354094
0.5074629769036451,0.5068016561066232
0.505864497696616,0.5063400006875759
0.5061293520878271,0.5229173462565352
0.5044632974973658,0.5079290154503613
0.5037260819802579,0.5060941824098912
0.5040627784028495,0.5047457828754331
0.5026920667475032,0.5063454479705997
0.5017797532923443,0.5028567023393584
0.50200904875072,0.5039111303120125
0.5022143974285764,0.5056318946001006
0.5001859270881132,0.5016178517806821
